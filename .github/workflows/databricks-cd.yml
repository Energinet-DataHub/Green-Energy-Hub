name: Databricks Deploy
# Run this workflow on demand
on:
  workflow_dispatch:
    inputs:
      resource_group_name:
        description: 'Resource Group Name'
        required: true
        default: 'energinettf'
      keyvault_name:
        description: 'Key Vault Name'
        required: true
        default: 'energinetkv'
      eventhub_namespace_name:
        description: 'EventHub Namespace Name'
        required: true
        default: 'energinet-ehn'
      input_eventhub_name:
        description: 'Input EventHub Name'
        required: true
        default: 'input'
      valid_output_eventhub_name:
        description: 'Valid Output EventHub Name'
        required: true
        default: 'valid-output'
      invalid_output_eventhub_name:
        description: 'Invalid Output EventHub Name'
        required: true
        default: 'invalid-output'
      storage_account_name:
        description: 'Storage Account Name'
        required: true
        default: 'energinetstrg1'
      app_name:
        description: 'Application Name'
        required: true
        default: 'datahub'

jobs:

  # Set the job key. The key is displayed as the job name
  # when a job name is not provided
  databricks_infra_deploy:
    # Name the Job
    name: Deploy databricks cluster and create job
    # Set the type of machine to run on
    runs-on: ubuntu-latest
    env:
      ARM_CLIENT_ID:  ${{ secrets.CLIENT_ID }}
      ARM_TENANT_ID:  ${{ secrets.TENANT_ID}}
      ARM_SUBSCRIPTION_ID:  ${{ secrets.SUBSCRIPTION_ID}}
      ARM_CLIENT_SECRET: ${{ secrets.CLIENT_SECRET }}
      TF_VAR_client_secret: ${{ secrets.CLIENT_SECRET }}
      TF_VAR_client_id: ${{ secrets.CLIENT_ID }}
      TF_VAR_tenant_id: ${{ secrets.TENANT_ID }}
      TF_VAR_object_id: ${{ secrets.OBJECT_ID }}

    steps:
        - name: Setup Terraform
          uses: hashicorp/setup-terraform@v1.2.1
          with:
            terraform_wrapper: false
        
        - name: Setup Python
          uses: actions/setup-python@v2
          with:
            python-version: '3.7' # Version range or exact version of a Python version to use, using SemVer's version range syntax
            architecture: 'x64' # optional x64 or x86. Defaults to x64 if not specified

        - name: Install Databricks CLI
          run: pip install --upgrade databricks-cli
        
        - name: Checkout code
          uses: actions/checkout@v2

        # Run only if workflow started on demand (manually triggered)
        - name: Set env
          run: |
            echo "TF_VAR_resource_group_name=${{ github.event.inputs.resource_group_name }}" >> $GITHUB_ENV
            echo "TF_VAR_keyvault_name=${{ github.event.inputs.keyvault_name }}" >> $GITHUB_ENV
            echo "TF_VAR_eventhub_namespace_name=${{ github.event.inputs.eventhub_namespace_name }}" >> $GITHUB_ENV
            echo "TF_VAR_input_eventhub_name=${{ github.event.inputs.input_eventhub_name }}" >> $GITHUB_ENV
            echo "TF_VAR_valid_output_eventhub_name=${{ github.event.inputs.valid_output_eventhub_name }}" >> $GITHUB_ENV
            echo "TF_VAR_invalid_output_eventhub_name=${{ github.event.inputs.invalid_output_eventhub_name }}" >> $GITHUB_ENV
            echo "TF_VAR_storage_account_name=${{ github.event.inputs.storage_account_name }}" >> $GITHUB_ENV
            echo "TF_VAR_app_name=${{ github.event.inputs.app_name }}" >> $GITHUB_ENV
          if:  github.event.inputs.app_name

        - name: Terraform Infra Init
          working-directory: ./build/terraform/infra
          id: init_infra
          run: terraform init
          
        - name: Terraform Infra Apply
          working-directory: ./build/terraform/infra
          id: apply_infra
          run: terraform apply -no-color -auto-approve
          continue-on-error: false           
          
        - name: Set env Infra
          working-directory: ./build/terraform/infra
          run: |
            echo "TF_VAR_databricks_id=$(terraform output databricks_id)" >> $GITHUB_ENV
            echo "TF_VAR_databricks_workspace_id=$(terraform output databricks_workspace_id)" >> $GITHUB_ENV
            echo ::add-mask::$(terraform output input_eh_listen_connection_string)
            echo "TF_VAR_input_eh_listen_connection_string=$(terraform output input_eh_listen_connection_string)" >> $GITHUB_ENV
            echo "databricks_url=$(terraform output databricks_workspace_url)" >> $GITHUB_ENV
            echo ::add-mask::$(terraform output valid_output_eh_send_connection_string)
            echo "TF_VAR_valid_output_eh_send_connection_string=$(terraform output valid_output_eh_send_connection_string)" >> $GITHUB_ENV
            echo ::add-mask::$(terraform output invalid_output_eh_send_connection_string)
            echo "TF_VAR_invalid_output_eh_send_connection_string=$(terraform output invalid_output_eh_send_connection_string)" >> $GITHUB_ENV
            echo ::add-mask::$(terraform output storage_key)
            echo "TF_VAR_storage_key=$(terraform output storage_key)" >> $GITHUB_ENV 
            echo "TF_VAR_storage_name=$(terraform output storage_name)" >> $GITHUB_ENV
            echo "TF_VAR_streaming_container_name=$(terraform output streaming_container_name)" >> $GITHUB_ENV
            echo "TF_VAR_python_main_file=dbfs:/streaming/enrichment_and_validation.py" >> $GITHUB_ENV
            echo "TF_VAR_wheel_file=dbfs:/streaming/geh_stream-1.0-py3-none-any.whl" >> $GITHUB_ENV
            echo ::add-mask::$(terraform output telemetry_instrumentation_key)
            echo "TF_VAR_telemetry_instrumentation_key=$(terraform output telemetry_instrumentation_key)" >> $GITHUB_ENV

         #Override for Dev Purposes only, to be deleted later
         #- name: Override App Insights Settings
         #  working-directory: ./build/terraform/infra
         #  run: |
         #    echo "TF_VAR_telemetry_instrumentation_key=<Instrumentation_Key>" >> $GITHUB_ENV   

        - name: Create Python Wheel for streaming job
          working-directory: ./src/streaming
          run: |
            pip install wheel
            python setup.py sdist bdist_wheel

        # resource id in curl request is fixed Azure Databricks resource id, Azure wide
        - name: Obtain AAD Token for Databricks CLI
          run: |
            curl_result=$(curl -X POST -H 'Content-Type: application/x-www-form-urlencoded' -d 'grant_type=client_credentials&client_id=${{env.ARM_CLIENT_ID}}&resource=2ff814a6-3304-4ab8-85cb-cd0e6f879c1d&client_secret=${{ secrets.CLIENT_SECRET }}' https://login.microsoftonline.com/${{env.ARM_TENANT_ID}}/oauth2/token) 
            token=$(echo $curl_result | python3 -c "import sys, json; print(json.load(sys.stdin)['access_token'])")
            echo ::add-mask::$token
            echo "DATABRICKS_AAD_TOKEN=$token" >> $GITHUB_ENV
        
        # Wheel file name hardcoded now
        - name: Copy files to DBFS
          id: copy_files_todbfs
          run: |    
            databricks configure --host "https://${{env.databricks_url}}" --aad-token
            dbfs cp --overwrite ./src/streaming/enrichment_and_validation.py dbfs:/streaming/enrichment_and_validation.py
            dbfs cp -r --overwrite ./src/streaming/dist/geh_stream-1.0-py3-none-any.whl dbfs:/streaming/geh_stream-1.0-py3-none-any.whl
        
        # Create streaming job
        - name: Terraform Databricks Init
          working-directory: ./build/terraform/databricks
          id: init_databricks
          run: terraform init
                    
        - name: Terraform Databricks Apply
          working-directory: ./build/terraform/databricks
          id: apply_databricks
          run: terraform apply -no-color -auto-approve
          continue-on-error: false
          
        - name: Set env Databricks
          working-directory: ./build/terraform/databricks
          run: |
            echo "databricks_job_id=$(terraform output databricks_job_id)" >> $GITHUB_ENV
        
        # resource in command must match with resource name in main.tf
        # after feature: https://github.com/databrickslabs/terraform-provider-databricks/issues/389 
        # is available this should be changed and job should not be recreated on each run
        - name: Force recreation of databricks job on next run
          working-directory: ./build/terraform/databricks
          run: |
            terraform taint databricks_job.streaming_job
         
        - name: Databricks CLI run the job
          id: run_job
          run: |
            res=$(databricks jobs run-now --job-id ${{env.databricks_job_id}})
            run_id=$(echo $res | python -c "import sys, json; print(json.load(sys.stdin)['run_id'])")
            echo "::set-output name=run_id::$run_id"
            
        - name: Check Job Status
          working-directory: ./build
          run: |
            pip install configargparse
            pip install requests
            python -u job_status_check.py --job-run-ids  ${{steps.run_job.outputs.run_id}} --retries 2 --databricks-url 'https://${{env.databricks_url}}' --token ${{env.DATABRICKS_AAD_TOKEN}}