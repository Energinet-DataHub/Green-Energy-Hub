name: Databricks Infrastructure Deploy
# Run this workflow on demand
on:
  push:
  workflow_dispatch:

jobs:
  databricks_infra_deploy:
    
    # Name the Job
    name: Deploy databricks workspace
    # Set the type of machine to run on
    runs-on: ubuntu-latest

    steps:

      - name: Checkout code
        uses: actions/checkout@v2
        
      - name: Read Pipeline Configuration
        uses: ./.github/actions/read-pipeline-configuration

      - name: Read Client Secret
        env:
          SECRET_NAME: CLIENT_SECRET_${{ env.UPPERCASE_ENV_NAME }}
        run: |  
          echo "ARM_CLIENT_SECRET=${{ secrets[env.SECRET_NAME] }}" >> $GITHUB_ENV

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v1.2.1
        with:
          terraform_wrapper: false
      
      - name: Setup Python
        uses: actions/setup-python@v2
        with:
          python-version: '3.7' # Version range or exact version of a Python version to use, using SemVer's version range syntax
          architecture: 'x64' # optional x64 or x86. Defaults to x64 if not specified

      - name: Azure CLI Install and Login
        uses: ./.github/actions/azure-cli-install-login
      
      - name: Check If Terraform State Storage exists
        id: state-storage-exists
        run: |
          storage_exists=$(az storage account check-name --name 'enrgtfstate${{ env.ENV_NAME }}' | python3 -c "import sys, json; print(not json.load(sys.stdin)['nameAvailable'])")
          echo "::set-output name=state-storage-exists::${storage_exists}"

      #Create TF State Container if needed
      - name: Create Terraform State Storage
        run: |
          storage_name="enrgtfstate${{ env.ENV_NAME }}"
          az storage account create --resource-group ${{ env.RESOURCE_GROUP_NAME }} --name $storage_name --sku Standard_LRS --encryption-services blob
          account_key=$(az storage account keys list --resource-group ${{ env.RESOURCE_GROUP_NAME }} --account-name $storage_name --query '[0].value' -o tsv)
          az storage container create --name tfstate --account-name $storage_name --account-key $account_key
        if: steps.state-storage-exists.outputs.state-storage-exists == 'False'
      
      - name: Set TF Vars
        run: |
          echo "TF_VAR_client_secret=${{ env.ARM_CLIENT_SECRET }}" >> $GITHUB_ENV
          echo "TF_VAR_tenant_id=${{ env.ARM_TENANT_ID }}" >> $GITHUB_ENV
          echo "TF_VAR_client_id=${{ env.ARM_CLIENT_ID }}" >> $GITHUB_ENV
          echo "TF_VAR_object_id=${{ env.ARM_OBJECT_ID }}" >> $GITHUB_ENV
          echo "TF_VAR_resource_group_name=${{ env.RESOURCE_GROUP_NAME }}" >> $GITHUB_ENV
          echo "TF_VAR_appinsights_name=appidatahub${{ env.ENV_NAME }}" >> $GITHUB_ENV
          echo "TF_VAR_keyvault_name=energinetkv${{ env.ENV_NAME }}" >> $GITHUB_ENV
          echo "TF_VAR_eventhub_namespace_name=energinet-ehn-${{ env.ENV_NAME }}" >> $GITHUB_ENV
          echo "TF_VAR_input_eventhub_name=input" >> $GITHUB_ENV
          echo "TF_VAR_valid_output_eventhub_name=valid-output" >> $GITHUB_ENV
          echo "TF_VAR_invalid_output_eventhub_name=invalid-output" >> $GITHUB_ENV
          echo "TF_VAR_storage_account_name=enrgnt${{ env.ENV_NAME }}" >> $GITHUB_ENV
          echo "TF_VAR_databricks_name=energinetdbricks-${{ env.ENV_NAME }}" >> $GITHUB_ENV

      - name: Configure Terraform Backend
        uses: ./.github/actions/configure-terraform-backend
        with:
          backend-file-path: "./build/terraform/infra/backend.tf"
          resource-group-name: "enrgtfstate${{ env.RESOURCE_GROUP_NAME }}"
          storage-account-name: "enrgtfstate${{ env.ENV_NAME }}"

      - name: Terraform Infra Init
        working-directory: ./build/terraform/infra
        run: terraform init

      - name: Terraform Infra Plan
        working-directory: ./build/terraform/infra
        run: terraform plan
        
      - name: Terraform Infra Apply
        id: terraform-apply
        working-directory: ./build/terraform/infra
        run: |
          terraform apply -no-color -auto-approve
          echo "::set-output name=workspace-url::$(terraform output databricks_workspace_url)"
        continue-on-error: false